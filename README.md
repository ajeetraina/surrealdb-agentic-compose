# SurrealDB Agentic Compose with LangChain Multi-Model RAG

A sophisticated multi-agent AI system built with Google's ADK (Agno) and enhanced with LangChain's multi-model RAG capabilities using SurrealDB. This system demonstrates how agents can build persistent, graph-based memory across sessions using vector search, knowledge graphs, and hybrid retrieval strategies.

## ğŸŒŸ What's New

This version adds **LangChain Multi-Model RAG** capabilities inspired by the [SurrealDB blog post](https://surrealdb.com/blog/multi-model-rag-with-langchain):

- **ğŸ” Vector Search**: Semantic similarity search for agent outputs and research findings
- **ğŸ•¸ï¸ Knowledge Graph**: Graph-based relationships between documents and extracted keywords
- **ğŸ”„ Hybrid Retrieval**: Combines vector search + graph traversal for superior context retrieval
- **ğŸ·ï¸ Automatic Keyword Extraction**: LLM-powered keyword inference from agent outputs
- **ğŸ“Š Multi-Model Storage**: Leverages SurrealDB's document, graph, and vector capabilities

## Why SurrealDB for AI Agents

- Agents need to remember conversations, context, and state
- Graph Relationships for Multi-Agent Systems
- Agents can subscribe to changes (WebSocket support)
- When one agent updates data, others are notified instantly.


## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        User Interface                        â”‚
â”‚                    (Flask Web App - :8080)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Agent Layer (ADK)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Coordinator  â”‚â”€â”€â”‚ Researcher   â”‚â”€â”€â”‚  Analyst     â”‚      â”‚
â”‚  â”‚    Agent     â”‚  â”‚    Agent     â”‚  â”‚   Agent      â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LangChain RAG Pipeline                          â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Ingestion      â”‚  â”‚      Retrieval              â”‚     â”‚
â”‚  â”‚   - Documents    â”‚  â”‚   - Vector Search           â”‚     â”‚
â”‚  â”‚   - Keywords     â”‚  â”‚   - Graph Traversal         â”‚     â”‚
â”‚  â”‚   - Graph Build  â”‚  â”‚   - Hybrid Combination      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 SurrealDB (Multi-Model)                     â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Vector    â”‚  â”‚    Graph    â”‚  â”‚  Document   â”‚        â”‚
â”‚  â”‚    Store    â”‚  â”‚    Store    â”‚  â”‚    Store    â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- **Docker Desktop 4.43.0+** or **Docker Engine**
- **GPU-enabled system** (for local models) OR **OpenAI API key**
- **Docker Compose 2.38.1+** (if using Docker Engine on Linux)

### 1. Clone & Setup

```bash
cd surrealdb-agentic-compose-enhanced
cp mcp.env.example .mcp.env
# Edit .mcp.env if you want to configure MCP servers
```

### 2. Choose Your Model Provider

#### Option A: Local Models (Requires GPU)

```bash
docker compose up --build
```

#### Option B: OpenAI Models

```bash
# Create API key file
echo "sk-your-api-key-here" > secret.openai-api-key

# Start with OpenAI configuration
docker compose -f compose.yaml -f compose.openai.yaml up --build
```

### 3. Access the Application

- **Web Interface**: http://localhost:8080
- **Surrealist UI**: http://localhost:8081
- **MCP Gateway**: http://localhost:8811

## ğŸ’¡ How It Works

### Multi-Model RAG Flow

1. **Ingestion Pipeline**
   ```
   Agent Output/Research Finding
   â†“
   Extract Keywords (LLM)
   â†“
   Generate Embeddings
   â†“
   Store in:
   - Vector Store (conversations)
   - Vector Store (keywords)  
   - Graph Store (documentâ†’keyword relationships)
   ```

2. **Hybrid Retrieval**
   ```
   User Query
   â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Vector Search  â”‚ Graph Traversal â”‚
   â”‚  (Semantic)     â”‚ (Relationships) â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                 â”‚
            â””â”€â”€â”€â”€â”€â”€ Merge â”€â”€â”€â”€â”˜
                     â†“
            Re-rank & Combine
                     â†“
            Context for LLM
   ```

3. **Agent Coordination**
   ```
   User Request
   â†“
   Coordinator Agent
   â†“
   Check Past Context (Hybrid Retrieval)
   â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Researcher Agent   â”‚ Analyst Agent  â”‚
   â”‚ (Gather Info)      â”‚ (Analyze)      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â†“
   Store Results (Ingestion)
   â†“
   Return to User
   ```

## ğŸ“Š Example Interactions

### First Query: Research
```
Query: "What are the latest trends in containerization?"

Process:
1. Coordinator routes to Researcher
2. Researcher searches web via MCP Gateway
3. Findings stored in SurrealDB with embeddings
4. Keywords extracted: ["containerization", "docker", "kubernetes", "trends"]
5. Graph relationships created
```

### Follow-up Query: Analysis with Context
```
Query: "How does Docker Compose help with the containerization we discussed?"

Process:
1. Hybrid retrieval finds previous containerization research
2. Vector search: matches "docker compose" and "containerization"
3. Graph traversal: finds documents linked to "containerization" keyword
4. Analyst receives enriched context from past research
5. Response references previous findings naturally
```

### Memory Query
```
Query: "What did we learn about Docker earlier?"

Process:
1. Vector search on "docker" finds semantically related docs
2. Graph traversal finds all docs connected to "docker" keyword
3. Returns timestamped findings in chronological order
```

## ğŸ”§ Configuration

### Environment Variables

```bash
# SurrealDB
SURREAL_URL=ws://surrealdb:8000/rpc
SURREAL_NS=agents
SURREAL_DB=memory
SURREAL_USER=root
SURREAL_PASS=root

# Embedding Model
EMBEDDING_MODEL=all-minilm:22m
USE_OPENAI=false

# RAG Parameters
VECTOR_THRESHOLD=0.3  # Similarity threshold (0-1)
VECTOR_K=5           # Number of vector results
GRAPH_LIMIT=5        # Number of graph results

# Keyword Extraction
KEYWORD_MODEL=llama3.2
```

### Tuning RAG Performance

**Vector Search Threshold** (`VECTOR_THRESHOLD`):
- Lower (0.2-0.3): More results, may include less relevant docs
- Higher (0.4-0.6): Fewer results, more precise matches
- Default: 0.3 works well for most cases

**K Value** (`VECTOR_K`):
- How many top results to retrieve
- Typically 3-10 depending on context window size
- Default: 5 balances context richness and token usage

